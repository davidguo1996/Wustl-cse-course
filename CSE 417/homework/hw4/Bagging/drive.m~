n =200;

load zip.train;

fprintf('Working on the one-vs-three problem...\n\n');
subsample = zip(find(zip(:,1)==1 | zip(:,1) == 3),:);
Y = subsample(:,1);
X = subsample(:,2:257);
ct = fitctree(X,Y,'CrossVal','on');
fprintf('The cross-validation error of decision trees is %.4f\n', ct.kfoldLoss);

%%%

%%
[oob] = plot(X,Y,200);


bee=oob(200,1)
fprintf('The OOB error of 200 bagged decision trees is %.4f\n', bee);

x_axis = 1:1:n;
plot(x_axis,oob,'LineWidth',1);
%legend()
xlabel('numBags');
ylabel('oob');
title('oob under numBags');
oobErr = oob(numBags);